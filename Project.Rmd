---
title: "Course Project"
author: "Fernando Braga"
date: "8 de maio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

Wearable devices made possible to collect data about personal activity. Human Activity Recognition project (held on <http://groupware.les.inf.puc-rio.br/har>) released a dataset on Weight Lifting observations, focusing on the quality of the exercise itself, and based on these observations we'll try to predict whether an individual did well on the exercises.

## Analysis

#### Loading and Cleaning Data

```{r rawdata}
rm(list=ls())
library(ggplot2);library(caret)
set.seed(34857)

raw.train <- read.csv('pml-training.csv', na.strings = c("","NA"))
raw.test  <- read.csv('pml-testing.csv')
```

Observing raw data, there are multiple columns that are summarizing data. They only have data when new_window variable is yes. The following code will remove this columns so we can get tidy data. Near Zero columns will also be removed.

```{r tidydata}

tidy.train <- raw.train[!colSums(is.na(raw.train)) > nrow(raw.train)* 0.95 ]
tidy.test  <- raw.test [!colSums(is.na(raw.test )) > nrow(raw.test )* 0.95 ]

columns_not_needed <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window", "classe", "problem_id" )
features <- names( tidy.train ) [!(names( tidy.train ) %in% columns_not_needed)]

tidy.train <- tidy.train[ ,c( features, "classe") ]
tidy.test  <- tidy.test [ ,c( features, "problem_id") ]

# x <- nearZeroVar(tidy.train, saveMetrics=TRUE)
# x$varname <- rownames(x)
# tidy.train <- tidy.train[,colnames(tidy.train)!=c(x[x$nzv == TRUE,]$varname)]
# 
# rm(x)
```

We'll set 30% of the data aside for validation purposes.

```{r splittingsets}
inBuild    <- createDataPartition(y=tidy.train$classe,p=0.7,list=FALSE)
buildData  <- tidy.train[inBuild,]
validation <- tidy.train[-inBuild,]

inTrain  <- createDataPartition(y=buildData$classe,p=0.7,list=FALSE)
training <- buildData[inTrain,]
testing  <- buildData[-inTrain,]
```

## Training 

```{r rftraining}
invisible(library(randomForest))
invisible(library(foreach))

# cluster <- makeCluster(detectCores() - 1)
# cluster <- makeCluster( 2 )
# setDefaultCluster( cluster )
# rfParam <- expand.grid( mtry = round(sqrt(ncol( buildData ))), importance = TRUE )
train_control <- trainControl(method="cv", number=10, allowParallel = TRUE)

start_time <- proc.time()
m_tree <- train(classe ~ ., data = training, method = 'rf', 
	trControl=train_control)
print( proc.time() - start_time)

# stopCluster(cluster)
```

```{r plot, echo=FALSE}
plot(m_tree)
```
```{r gbmtesting}
p_tree <- predict(m_tree,testing)
print(confusionMatrix(p_tree, testing$classe))
print(confusionMatrix(p_tree, testing$classe)$overall[ 'Accuracy' ])

```

We managed to get 99% accuracy ! Let's try on validation set!

```{r gbmvalidation}
v_tree <- predict(m_tree,validation)
print(confusionMatrix(v_tree, validation$classe))
print(confusionMatrix(v_tree, validation$classe)$overall[ 'Accuracy' ])
```

99% accuracy on validation set! Let's do the Quiz!!

## Final test with 20 test cases

```{r testcase}
final.pred <- predict( m_tree, raw.test )
print(final.pred)
```
